{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Technight27/Python-Codes-Data-Science/blob/main/Aug_23_DS_Day_9_Data_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09f1ebd9",
      "metadata": {
        "id": "09f1ebd9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b923e1f",
      "metadata": {
        "id": "0b923e1f",
        "outputId": "048e4255-348f-4a6e-cbb4-8413c3ff26c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'C:\\\\Users\\\\noble'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbfe5956",
      "metadata": {
        "id": "bbfe5956"
      },
      "outputs": [],
      "source": [
        "os.chdir ('C:\\\\Noble\\\\Training\\\\Acmegrade\\\\Data Science\\\\19 Aug 2023\\\\Aug 23 DS Day9\\\\')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57889086",
      "metadata": {
        "id": "57889086",
        "outputId": "c1059e7a-3546-4a67-db8d-42116bc29cf8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Country</th>\n",
              "      <th>Age</th>\n",
              "      <th>Salary</th>\n",
              "      <th>Purchased</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>France</td>\n",
              "      <td>44.0</td>\n",
              "      <td>72000.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>27.0</td>\n",
              "      <td>48000.0</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Germany</td>\n",
              "      <td>NaN</td>\n",
              "      <td>54000.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Spain</td>\n",
              "      <td>39.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Germany</td>\n",
              "      <td>NaN</td>\n",
              "      <td>64000.0</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>France</td>\n",
              "      <td>35.0</td>\n",
              "      <td>58000.0</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Spain</td>\n",
              "      <td>39.0</td>\n",
              "      <td>52000.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>France</td>\n",
              "      <td>48.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Germany</td>\n",
              "      <td>50.0</td>\n",
              "      <td>83000.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>France</td>\n",
              "      <td>37.0</td>\n",
              "      <td>67000.0</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Country   Age   Salary  Purchased \n",
              "0   France   44.0  72000.0         No\n",
              "1       NaN  27.0  48000.0        Yes\n",
              "2  Germany    NaN  54000.0         No\n",
              "3    Spain   39.0      NaN         No\n",
              "4  Germany    NaN  64000.0        Yes\n",
              "5   France   35.0  58000.0        Yes\n",
              "6    Spain   39.0  52000.0         No\n",
              "7   France   48.0      NaN        Yes\n",
              "8  Germany   50.0  83000.0         No\n",
              "9   France   37.0  67000.0        Yes"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1= pd.read_excel('Data Preprocessing Data File.xlsx')\n",
        "df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91421481",
      "metadata": {
        "id": "91421481",
        "outputId": "7d2f90a2-a9b5-4e30-9a85-8363016d9fe0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Country</th>\n",
              "      <th>Age</th>\n",
              "      <th>Salary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>France</td>\n",
              "      <td>44.0</td>\n",
              "      <td>72000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>27.0</td>\n",
              "      <td>48000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Germany</td>\n",
              "      <td>NaN</td>\n",
              "      <td>54000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Spain</td>\n",
              "      <td>39.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Germany</td>\n",
              "      <td>NaN</td>\n",
              "      <td>64000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>France</td>\n",
              "      <td>35.0</td>\n",
              "      <td>58000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Spain</td>\n",
              "      <td>39.0</td>\n",
              "      <td>52000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>France</td>\n",
              "      <td>48.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Germany</td>\n",
              "      <td>50.0</td>\n",
              "      <td>83000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>France</td>\n",
              "      <td>37.0</td>\n",
              "      <td>67000.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Country   Age   Salary \n",
              "0   France   44.0  72000.0\n",
              "1       NaN  27.0  48000.0\n",
              "2  Germany    NaN  54000.0\n",
              "3    Spain   39.0      NaN\n",
              "4  Germany    NaN  64000.0\n",
              "5   France   35.0  58000.0\n",
              "6    Spain   39.0  52000.0\n",
              "7   France   48.0      NaN\n",
              "8  Germany   50.0  83000.0\n",
              "9   France   37.0  67000.0"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = df1.iloc[:,:-1]\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f63bbd4",
      "metadata": {
        "id": "6f63bbd4",
        "outputId": "64bbf28f-3ca0-4f05-c4f8-715235c8b1ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([['France ', 44.0, 72000.0],\n",
              "       [nan, 27.0, 48000.0],\n",
              "       ['Germany ', nan, 54000.0],\n",
              "       ['Spain ', 39.0, nan],\n",
              "       ['Germany ', nan, 64000.0],\n",
              "       ['France ', 35.0, 58000.0],\n",
              "       ['Spain ', 39.0, 52000.0],\n",
              "       ['France ', 48.0, nan],\n",
              "       ['Germany ', 50.0, 83000.0],\n",
              "       ['France ', 37.0, 67000.0]], dtype=object)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = df1.iloc[:,:-1].values\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61fd638e",
      "metadata": {
        "id": "61fd638e"
      },
      "outputs": [],
      "source": [
        "import sklearn.impute as im\n",
        "si = im.SimpleImputer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6712d49",
      "metadata": {
        "id": "b6712d49",
        "outputId": "2d85b820-5ae4-45c7-c1ce-69eb799418f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['France ', nan, 'Germany ', 'Spain ', 'Germany ', 'France ',\n",
              "       'Spain ', 'France ', 'Germany ', 'France '], dtype=object)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "caee9771",
      "metadata": {
        "id": "caee9771",
        "outputId": "8a62b023-7c6f-4b41-b325-f0dbf0326474"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([['France '],\n",
              "       [nan],\n",
              "       ['Germany '],\n",
              "       ['Spain '],\n",
              "       ['Germany '],\n",
              "       ['France '],\n",
              "       ['Spain '],\n",
              "       ['France '],\n",
              "       ['Germany '],\n",
              "       ['France ']], dtype=object)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[:,0:1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5785087e",
      "metadata": {
        "id": "5785087e",
        "outputId": "b8b4a83d-5ef2-4748-d226-3c498ac0bc95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([['France '],\n",
              "       ['France '],\n",
              "       ['Germany '],\n",
              "       ['Spain '],\n",
              "       ['Germany '],\n",
              "       ['France '],\n",
              "       ['Spain '],\n",
              "       ['France '],\n",
              "       ['Germany '],\n",
              "       ['France ']], dtype=object)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "si = SimpleImputer(strategy ='most_frequent')\n",
        "si.fit_transform (x[:,0:1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8112ed48",
      "metadata": {
        "id": "8112ed48",
        "outputId": "6325e4f8-d72b-4cf1-eae2-6f0a05e31998"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on SimpleImputer in module sklearn.impute._base object:\n",
            "\n",
            "class SimpleImputer(_BaseImputer)\n",
            " |  SimpleImputer(*, missing_values=nan, strategy='mean', fill_value=None, verbose=0, copy=True, add_indicator=False)\n",
            " |  \n",
            " |  Imputation transformer for completing missing values.\n",
            " |  \n",
            " |  Read more in the :ref:`User Guide <impute>`.\n",
            " |  \n",
            " |  .. versionadded:: 0.20\n",
            " |     `SimpleImputer` replaces the previous `sklearn.preprocessing.Imputer`\n",
            " |     estimator which is now removed.\n",
            " |  \n",
            " |  Parameters\n",
            " |  ----------\n",
            " |  missing_values : int, float, str, np.nan or None, default=np.nan\n",
            " |      The placeholder for the missing values. All occurrences of\n",
            " |      `missing_values` will be imputed. For pandas' dataframes with\n",
            " |      nullable integer dtypes with missing values, `missing_values`\n",
            " |      should be set to `np.nan`, since `pd.NA` will be converted to `np.nan`.\n",
            " |  \n",
            " |  strategy : str, default='mean'\n",
            " |      The imputation strategy.\n",
            " |  \n",
            " |      - If \"mean\", then replace missing values using the mean along\n",
            " |        each column. Can only be used with numeric data.\n",
            " |      - If \"median\", then replace missing values using the median along\n",
            " |        each column. Can only be used with numeric data.\n",
            " |      - If \"most_frequent\", then replace missing using the most frequent\n",
            " |        value along each column. Can be used with strings or numeric data.\n",
            " |        If there is more than one such value, only the smallest is returned.\n",
            " |      - If \"constant\", then replace missing values with fill_value. Can be\n",
            " |        used with strings or numeric data.\n",
            " |  \n",
            " |      .. versionadded:: 0.20\n",
            " |         strategy=\"constant\" for fixed value imputation.\n",
            " |  \n",
            " |  fill_value : str or numerical value, default=None\n",
            " |      When strategy == \"constant\", fill_value is used to replace all\n",
            " |      occurrences of missing_values.\n",
            " |      If left to the default, fill_value will be 0 when imputing numerical\n",
            " |      data and \"missing_value\" for strings or object data types.\n",
            " |  \n",
            " |  verbose : int, default=0\n",
            " |      Controls the verbosity of the imputer.\n",
            " |  \n",
            " |  copy : bool, default=True\n",
            " |      If True, a copy of `X` will be created. If False, imputation will\n",
            " |      be done in-place whenever possible. Note that, in the following cases,\n",
            " |      a new copy will always be made, even if `copy=False`:\n",
            " |  \n",
            " |      - If `X` is not an array of floating values;\n",
            " |      - If `X` is encoded as a CSR matrix;\n",
            " |      - If `add_indicator=True`.\n",
            " |  \n",
            " |  add_indicator : bool, default=False\n",
            " |      If True, a :class:`MissingIndicator` transform will stack onto output\n",
            " |      of the imputer's transform. This allows a predictive estimator\n",
            " |      to account for missingness despite imputation. If a feature has no\n",
            " |      missing values at fit/train time, the feature won't appear on\n",
            " |      the missing indicator even if there are missing values at\n",
            " |      transform/test time.\n",
            " |  \n",
            " |  Attributes\n",
            " |  ----------\n",
            " |  statistics_ : array of shape (n_features,)\n",
            " |      The imputation fill value for each feature.\n",
            " |      Computing statistics can result in `np.nan` values.\n",
            " |      During :meth:`transform`, features corresponding to `np.nan`\n",
            " |      statistics will be discarded.\n",
            " |  \n",
            " |  indicator_ : :class:`~sklearn.impute.MissingIndicator`\n",
            " |      Indicator used to add binary indicators for missing values.\n",
            " |      `None` if `add_indicator=False`.\n",
            " |  \n",
            " |  n_features_in_ : int\n",
            " |      Number of features seen during :term:`fit`.\n",
            " |  \n",
            " |      .. versionadded:: 0.24\n",
            " |  \n",
            " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
            " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
            " |      has feature names that are all strings.\n",
            " |  \n",
            " |      .. versionadded:: 1.0\n",
            " |  \n",
            " |  See Also\n",
            " |  --------\n",
            " |  IterativeImputer : Multivariate imputation of missing values.\n",
            " |  \n",
            " |  Notes\n",
            " |  -----\n",
            " |  Columns which only contained missing values at :meth:`fit` are discarded\n",
            " |  upon :meth:`transform` if strategy is not `\"constant\"`.\n",
            " |  \n",
            " |  Examples\n",
            " |  --------\n",
            " |  >>> import numpy as np\n",
            " |  >>> from sklearn.impute import SimpleImputer\n",
            " |  >>> imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
            " |  >>> imp_mean.fit([[7, 2, 3], [4, np.nan, 6], [10, 5, 9]])\n",
            " |  SimpleImputer()\n",
            " |  >>> X = [[np.nan, 2, 3], [4, np.nan, 6], [10, np.nan, 9]]\n",
            " |  >>> print(imp_mean.transform(X))\n",
            " |  [[ 7.   2.   3. ]\n",
            " |   [ 4.   3.5  6. ]\n",
            " |   [10.   3.5  9. ]]\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      SimpleImputer\n",
            " |      _BaseImputer\n",
            " |      sklearn.base.TransformerMixin\n",
            " |      sklearn.base.BaseEstimator\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, *, missing_values=nan, strategy='mean', fill_value=None, verbose=0, copy=True, add_indicator=False)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  fit(self, X, y=None)\n",
            " |      Fit the imputer on `X`.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
            " |          Input data, where `n_samples` is the number of samples and\n",
            " |          `n_features` is the number of features.\n",
            " |      \n",
            " |      y : Ignored\n",
            " |          Not used, present here for API consistency by convention.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : object\n",
            " |          Fitted estimator.\n",
            " |  \n",
            " |  inverse_transform(self, X)\n",
            " |      Convert the data back to the original representation.\n",
            " |      \n",
            " |      Inverts the `transform` operation performed on an array.\n",
            " |      This operation can only be performed after :class:`SimpleImputer` is\n",
            " |      instantiated with `add_indicator=True`.\n",
            " |      \n",
            " |      Note that `inverse_transform` can only invert the transform in\n",
            " |      features that have binary indicators for missing values. If a feature\n",
            " |      has no missing values at `fit` time, the feature won't have a binary\n",
            " |      indicator, and the imputation done at `transform` time won't be\n",
            " |      inverted.\n",
            " |      \n",
            " |      .. versionadded:: 0.24\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape                 (n_samples, n_features + n_features_missing_indicator)\n",
            " |          The imputed data to be reverted to original data. It has to be\n",
            " |          an augmented array of imputed data and the missing indicator mask.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      X_original : ndarray of shape (n_samples, n_features)\n",
            " |          The original `X` with missing values as it was prior\n",
            " |          to imputation.\n",
            " |  \n",
            " |  transform(self, X)\n",
            " |      Impute all missing values in `X`.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
            " |          The input data to complete.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      X_imputed : {ndarray, sparse matrix} of shape                 (n_samples, n_features_out)\n",
            " |          `X` with imputed values.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.TransformerMixin:\n",
            " |  \n",
            " |  fit_transform(self, X, y=None, **fit_params)\n",
            " |      Fit to data, then transform it.\n",
            " |      \n",
            " |      Fits transformer to `X` and `y` with optional parameters `fit_params`\n",
            " |      and returns a transformed version of `X`.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Input samples.\n",
            " |      \n",
            " |      y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n",
            " |          Target values (None for unsupervised transformations).\n",
            " |      \n",
            " |      **fit_params : dict\n",
            " |          Additional fit parameters.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      X_new : ndarray array of shape (n_samples, n_features_new)\n",
            " |          Transformed array.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from sklearn.base.TransformerMixin:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __repr__(self, N_CHAR_MAX=700)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  get_params(self, deep=True)\n",
            " |      Get parameters for this estimator.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      deep : bool, default=True\n",
            " |          If True, will return the parameters for this estimator and\n",
            " |          contained subobjects that are estimators.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      params : dict\n",
            " |          Parameter names mapped to their values.\n",
            " |  \n",
            " |  set_params(self, **params)\n",
            " |      Set the parameters of this estimator.\n",
            " |      \n",
            " |      The method works on simple estimators as well as on nested objects\n",
            " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
            " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
            " |      possible to update each component of a nested object.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      **params : dict\n",
            " |          Estimator parameters.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : estimator instance\n",
            " |          Estimator instance.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help (si)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be740ac1",
      "metadata": {
        "id": "be740ac1",
        "outputId": "79f8cc25-3219-4d73-d395-f35c388ce858"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['France ' 44.0 72000.0]\n",
            " ['France ' 27.0 48000.0]\n",
            " ['Germany ' nan 54000.0]\n",
            " ['Spain ' 39.0 nan]\n",
            " ['Germany ' nan 64000.0]\n",
            " ['France ' 35.0 58000.0]\n",
            " ['Spain ' 39.0 52000.0]\n",
            " ['France ' 48.0 nan]\n",
            " ['Germany ' 50.0 83000.0]\n",
            " ['France ' 37.0 67000.0]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "si = SimpleImputer(strategy ='most_frequent')\n",
        "x[:,0:1] = si.fit_transform (x[:,0:1])\n",
        "print (x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38287938",
      "metadata": {
        "id": "38287938",
        "outputId": "9d0456a1-742b-4de6-804d-5fcec97c6053"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['France ' 44.0 72000.0]\n",
            " ['France ' 27.0 48000.0]\n",
            " ['Germany ' 39.875 54000.0]\n",
            " ['Spain ' 39.0 nan]\n",
            " ['Germany ' 39.875 64000.0]\n",
            " ['France ' 35.0 58000.0]\n",
            " ['Spain ' 39.0 52000.0]\n",
            " ['France ' 48.0 nan]\n",
            " ['Germany ' 50.0 83000.0]\n",
            " ['France ' 37.0 67000.0]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "si = SimpleImputer(strategy ='mean')\n",
        "x[:,1:2] = si.fit_transform (x[:,1:2])\n",
        "print (x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b809a631",
      "metadata": {
        "id": "b809a631",
        "outputId": "2e9dde52-a8df-4637-90b2-cadbcee3a01f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['France ' 44.0 72000.0]\n",
            " ['France ' 27.0 48000.0]\n",
            " ['Germany ' 39.875 54000.0]\n",
            " ['Spain ' 39.0 62250.0]\n",
            " ['Germany ' 39.875 64000.0]\n",
            " ['France ' 35.0 58000.0]\n",
            " ['Spain ' 39.0 52000.0]\n",
            " ['France ' 48.0 62250.0]\n",
            " ['Germany ' 50.0 83000.0]\n",
            " ['France ' 37.0 67000.0]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "si = SimpleImputer()\n",
        "x[:,2:] = si.fit_transform (x[:,2:])\n",
        "print (x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52731b09",
      "metadata": {
        "id": "52731b09"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "si = SimpleImputer()\n",
        "x[:,2:] = si.fit_transform (x[:,2:])\n",
        "print (x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9df3f07",
      "metadata": {
        "id": "b9df3f07",
        "outputId": "a3f2ae1e-aabe-473c-d361-22bea815b7d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['France ', 'France ', 'Germany ', 'Spain ', 'Germany ', 'France ',\n",
              "       'Spain ', 'France ', 'Germany ', 'France '], dtype=object)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b7f366d",
      "metadata": {
        "id": "2b7f366d",
        "outputId": "d0d2b5ea-16b8-4c2d-ffcc-ea6186f93a2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 44.0, 72000.0],\n",
              "       [0, 27.0, 48000.0],\n",
              "       [1, 39.875, 54000.0],\n",
              "       [2, 39.0, 62250.0],\n",
              "       [1, 39.875, 64000.0],\n",
              "       [0, 35.0, 58000.0],\n",
              "       [2, 39.0, 52000.0],\n",
              "       [0, 48.0, 62250.0],\n",
              "       [1, 50.0, 83000.0],\n",
              "       [0, 37.0, 67000.0]], dtype=object)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "x[:,0] =le.fit_transform (x[:,0])\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33e1e9ae",
      "metadata": {
        "id": "33e1e9ae"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93ba80ce",
      "metadata": {
        "id": "93ba80ce",
        "outputId": "c7c0154b-60d4-4550-fb0b-2ab6ee63d180"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on class ColumnTransformer in module sklearn.compose._column_transformer:\n",
            "\n",
            "class ColumnTransformer(sklearn.base.TransformerMixin, sklearn.utils.metaestimators._BaseComposition)\n",
            " |  ColumnTransformer(transformers, *, remainder='drop', sparse_threshold=0.3, n_jobs=None, transformer_weights=None, verbose=False, verbose_feature_names_out=True)\n",
            " |  \n",
            " |  Applies transformers to columns of an array or pandas DataFrame.\n",
            " |  \n",
            " |  This estimator allows different columns or column subsets of the input\n",
            " |  to be transformed separately and the features generated by each transformer\n",
            " |  will be concatenated to form a single feature space.\n",
            " |  This is useful for heterogeneous or columnar data, to combine several\n",
            " |  feature extraction mechanisms or transformations into a single transformer.\n",
            " |  \n",
            " |  Read more in the :ref:`User Guide <column_transformer>`.\n",
            " |  \n",
            " |  .. versionadded:: 0.20\n",
            " |  \n",
            " |  Parameters\n",
            " |  ----------\n",
            " |  transformers : list of tuples\n",
            " |      List of (name, transformer, columns) tuples specifying the\n",
            " |      transformer objects to be applied to subsets of the data.\n",
            " |  \n",
            " |      name : str\n",
            " |          Like in Pipeline and FeatureUnion, this allows the transformer and\n",
            " |          its parameters to be set using ``set_params`` and searched in grid\n",
            " |          search.\n",
            " |      transformer : {'drop', 'passthrough'} or estimator\n",
            " |          Estimator must support :term:`fit` and :term:`transform`.\n",
            " |          Special-cased strings 'drop' and 'passthrough' are accepted as\n",
            " |          well, to indicate to drop the columns or to pass them through\n",
            " |          untransformed, respectively.\n",
            " |      columns :  str, array-like of str, int, array-like of int,                 array-like of bool, slice or callable\n",
            " |          Indexes the data on its second axis. Integers are interpreted as\n",
            " |          positional columns, while strings can reference DataFrame columns\n",
            " |          by name.  A scalar string or int should be used where\n",
            " |          ``transformer`` expects X to be a 1d array-like (vector),\n",
            " |          otherwise a 2d array will be passed to the transformer.\n",
            " |          A callable is passed the input data `X` and can return any of the\n",
            " |          above. To select multiple columns by name or dtype, you can use\n",
            " |          :obj:`make_column_selector`.\n",
            " |  \n",
            " |  remainder : {'drop', 'passthrough'} or estimator, default='drop'\n",
            " |      By default, only the specified columns in `transformers` are\n",
            " |      transformed and combined in the output, and the non-specified\n",
            " |      columns are dropped. (default of ``'drop'``).\n",
            " |      By specifying ``remainder='passthrough'``, all remaining columns that\n",
            " |      were not specified in `transformers` will be automatically passed\n",
            " |      through. This subset of columns is concatenated with the output of\n",
            " |      the transformers.\n",
            " |      By setting ``remainder`` to be an estimator, the remaining\n",
            " |      non-specified columns will use the ``remainder`` estimator. The\n",
            " |      estimator must support :term:`fit` and :term:`transform`.\n",
            " |      Note that using this feature requires that the DataFrame columns\n",
            " |      input at :term:`fit` and :term:`transform` have identical order.\n",
            " |  \n",
            " |  sparse_threshold : float, default=0.3\n",
            " |      If the output of the different transformers contains sparse matrices,\n",
            " |      these will be stacked as a sparse matrix if the overall density is\n",
            " |      lower than this value. Use ``sparse_threshold=0`` to always return\n",
            " |      dense.  When the transformed output consists of all dense data, the\n",
            " |      stacked result will be dense, and this keyword will be ignored.\n",
            " |  \n",
            " |  n_jobs : int, default=None\n",
            " |      Number of jobs to run in parallel.\n",
            " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
            " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
            " |      for more details.\n",
            " |  \n",
            " |  transformer_weights : dict, default=None\n",
            " |      Multiplicative weights for features per transformer. The output of the\n",
            " |      transformer is multiplied by these weights. Keys are transformer names,\n",
            " |      values the weights.\n",
            " |  \n",
            " |  verbose : bool, default=False\n",
            " |      If True, the time elapsed while fitting each transformer will be\n",
            " |      printed as it is completed.\n",
            " |  \n",
            " |  verbose_feature_names_out : bool, default=True\n",
            " |      If True, :meth:`get_feature_names_out` will prefix all feature names\n",
            " |      with the name of the transformer that generated that feature.\n",
            " |      If False, :meth:`get_feature_names_out` will not prefix any feature\n",
            " |      names and will error if feature names are not unique.\n",
            " |  \n",
            " |      .. versionadded:: 1.0\n",
            " |  \n",
            " |  Attributes\n",
            " |  ----------\n",
            " |  transformers_ : list\n",
            " |      The collection of fitted transformers as tuples of\n",
            " |      (name, fitted_transformer, column). `fitted_transformer` can be an\n",
            " |      estimator, 'drop', or 'passthrough'. In case there were no columns\n",
            " |      selected, this will be the unfitted transformer.\n",
            " |      If there are remaining columns, the final element is a tuple of the\n",
            " |      form:\n",
            " |      ('remainder', transformer, remaining_columns) corresponding to the\n",
            " |      ``remainder`` parameter. If there are remaining columns, then\n",
            " |      ``len(transformers_)==len(transformers)+1``, otherwise\n",
            " |      ``len(transformers_)==len(transformers)``.\n",
            " |  \n",
            " |  named_transformers_ : :class:`~sklearn.utils.Bunch`\n",
            " |      Read-only attribute to access any transformer by given name.\n",
            " |      Keys are transformer names and values are the fitted transformer\n",
            " |      objects.\n",
            " |  \n",
            " |  sparse_output_ : bool\n",
            " |      Boolean flag indicating whether the output of ``transform`` is a\n",
            " |      sparse matrix or a dense numpy array, which depends on the output\n",
            " |      of the individual transformers and the `sparse_threshold` keyword.\n",
            " |  \n",
            " |  output_indices_ : dict\n",
            " |      A dictionary from each transformer name to a slice, where the slice\n",
            " |      corresponds to indices in the transformed output. This is useful to\n",
            " |      inspect which transformer is responsible for which transformed\n",
            " |      feature(s).\n",
            " |  \n",
            " |      .. versionadded:: 1.0\n",
            " |  \n",
            " |  n_features_in_ : int\n",
            " |      Number of features seen during :term:`fit`. Only defined if the\n",
            " |      underlying transformers expose such an attribute when fit.\n",
            " |  \n",
            " |      .. versionadded:: 0.24\n",
            " |  \n",
            " |  See Also\n",
            " |  --------\n",
            " |  make_column_transformer : Convenience function for\n",
            " |      combining the outputs of multiple transformer objects applied to\n",
            " |      column subsets of the original feature space.\n",
            " |  make_column_selector : Convenience function for selecting\n",
            " |      columns based on datatype or the columns name with a regex pattern.\n",
            " |  \n",
            " |  Notes\n",
            " |  -----\n",
            " |  The order of the columns in the transformed feature matrix follows the\n",
            " |  order of how the columns are specified in the `transformers` list.\n",
            " |  Columns of the original feature matrix that are not specified are\n",
            " |  dropped from the resulting transformed feature matrix, unless specified\n",
            " |  in the `passthrough` keyword. Those columns specified with `passthrough`\n",
            " |  are added at the right to the output of the transformers.\n",
            " |  \n",
            " |  Examples\n",
            " |  --------\n",
            " |  >>> import numpy as np\n",
            " |  >>> from sklearn.compose import ColumnTransformer\n",
            " |  >>> from sklearn.preprocessing import Normalizer\n",
            " |  >>> ct = ColumnTransformer(\n",
            " |  ...     [(\"norm1\", Normalizer(norm='l1'), [0, 1]),\n",
            " |  ...      (\"norm2\", Normalizer(norm='l1'), slice(2, 4))])\n",
            " |  >>> X = np.array([[0., 1., 2., 2.],\n",
            " |  ...               [1., 1., 0., 1.]])\n",
            " |  >>> # Normalizer scales each row of X to unit norm. A separate scaling\n",
            " |  >>> # is applied for the two first and two last elements of each\n",
            " |  >>> # row independently.\n",
            " |  >>> ct.fit_transform(X)\n",
            " |  array([[0. , 1. , 0.5, 0.5],\n",
            " |         [0.5, 0.5, 0. , 1. ]])\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      ColumnTransformer\n",
            " |      sklearn.base.TransformerMixin\n",
            " |      sklearn.utils.metaestimators._BaseComposition\n",
            " |      sklearn.base.BaseEstimator\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, transformers, *, remainder='drop', sparse_threshold=0.3, n_jobs=None, transformer_weights=None, verbose=False, verbose_feature_names_out=True)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  fit(self, X, y=None)\n",
            " |      Fit all transformers using X.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, dataframe} of shape (n_samples, n_features)\n",
            " |          Input data, of which specified subsets are used to fit the\n",
            " |          transformers.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples,...), default=None\n",
            " |          Targets for supervised learning.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : ColumnTransformer\n",
            " |          This estimator.\n",
            " |  \n",
            " |  fit_transform(self, X, y=None)\n",
            " |      Fit all transformers, transform the data and concatenate results.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, dataframe} of shape (n_samples, n_features)\n",
            " |          Input data, of which specified subsets are used to fit the\n",
            " |          transformers.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples,), default=None\n",
            " |          Targets for supervised learning.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      X_t : {array-like, sparse matrix} of                 shape (n_samples, sum_n_components)\n",
            " |          Horizontally stacked results of transformers. sum_n_components is the\n",
            " |          sum of n_components (output dimension) over transformers. If\n",
            " |          any result is a sparse matrix, everything will be converted to\n",
            " |          sparse matrices.\n",
            " |  \n",
            " |  get_feature_names(self)\n",
            " |      DEPRECATED: get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            " |      \n",
            " |      Get feature names from all transformers.\n",
            " |      \n",
            " |          Returns\n",
            " |          -------\n",
            " |          feature_names : list of strings\n",
            " |              Names of the features produced by transform.\n",
            " |  \n",
            " |  get_feature_names_out(self, input_features=None)\n",
            " |      Get output feature names for transformation.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      input_features : array-like of str or None, default=None\n",
            " |          Input features.\n",
            " |      \n",
            " |          - If `input_features` is `None`, then `feature_names_in_` is\n",
            " |            used as feature names in. If `feature_names_in_` is not defined,\n",
            " |            then names are generated: `[x0, x1, ..., x(n_features_in_)]`.\n",
            " |          - If `input_features` is an array-like, then `input_features` must\n",
            " |            match `feature_names_in_` if `feature_names_in_` is defined.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      feature_names_out : ndarray of str objects\n",
            " |          Transformed feature names.\n",
            " |  \n",
            " |  get_params(self, deep=True)\n",
            " |      Get parameters for this estimator.\n",
            " |      \n",
            " |      Returns the parameters given in the constructor as well as the\n",
            " |      estimators contained within the `transformers` of the\n",
            " |      `ColumnTransformer`.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      deep : bool, default=True\n",
            " |          If True, will return the parameters for this estimator and\n",
            " |          contained subobjects that are estimators.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      params : dict\n",
            " |          Parameter names mapped to their values.\n",
            " |  \n",
            " |  set_params(self, **kwargs)\n",
            " |      Set the parameters of this estimator.\n",
            " |      \n",
            " |      Valid parameter keys can be listed with ``get_params()``. Note that you\n",
            " |      can directly set the parameters of the estimators contained in\n",
            " |      `transformers` of `ColumnTransformer`.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      **kwargs : dict\n",
            " |          Estimator parameters.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : ColumnTransformer\n",
            " |          This estimator.\n",
            " |  \n",
            " |  transform(self, X)\n",
            " |      Transform X separately by each transformer, concatenate results.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, dataframe} of shape (n_samples, n_features)\n",
            " |          The data to be transformed by subset.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      X_t : {array-like, sparse matrix} of                 shape (n_samples, sum_n_components)\n",
            " |          Horizontally stacked results of transformers. sum_n_components is the\n",
            " |          sum of n_components (output dimension) over transformers. If\n",
            " |          any result is a sparse matrix, everything will be converted to\n",
            " |          sparse matrices.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties defined here:\n",
            " |  \n",
            " |  named_transformers_\n",
            " |      Access the fitted transformer by name.\n",
            " |      \n",
            " |      Read-only attribute to access any transformer by given name.\n",
            " |      Keys are transformer names and values are the fitted transformer\n",
            " |      objects.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __abstractmethods__ = frozenset()\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from sklearn.base.TransformerMixin:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes inherited from sklearn.utils.metaestimators._BaseComposition:\n",
            " |  \n",
            " |  __annotations__ = {'steps': typing.List[typing.Any]}\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __repr__(self, N_CHAR_MAX=700)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(ColumnTransformer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3366f008",
      "metadata": {
        "id": "3366f008"
      },
      "outputs": [],
      "source": [
        " Parameters\n",
        " |  ----------\n",
        " |  transformers : list of tuples\n",
        " |      List of (name, transformer, columns) tuples specifying the\n",
        " |      transformer objects to be applied to subsets of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dafdf57",
      "metadata": {
        "id": "6dafdf57",
        "outputId": "bd7545fa-6011-4f2e-9849-4e6a94749725"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.0, 0.0, 0.0, 44.0, 72000.0],\n",
              "       [1.0, 0.0, 0.0, 27.0, 48000.0],\n",
              "       [0.0, 1.0, 0.0, 39.875, 54000.0],\n",
              "       [0.0, 0.0, 1.0, 39.0, 62250.0],\n",
              "       [0.0, 1.0, 0.0, 39.875, 64000.0],\n",
              "       [1.0, 0.0, 0.0, 35.0, 58000.0],\n",
              "       [0.0, 0.0, 1.0, 39.0, 52000.0],\n",
              "       [1.0, 0.0, 0.0, 48.0, 62250.0],\n",
              "       [0.0, 1.0, 0.0, 50.0, 83000.0],\n",
              "       [1.0, 0.0, 0.0, 37.0, 67000.0]], dtype=object)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct =  ColumnTransformer(transformers =[('one hot', OneHotEncoder(),[0])],remainder = 'passthrough')\n",
        "ct.fit_transform(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5211971c",
      "metadata": {
        "id": "5211971c",
        "outputId": "13c0c3bd-7b94-454c-dcd7-85da6e4aae8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 44.0, 72000.0],\n",
              "       [0, 27.0, 48000.0],\n",
              "       [1, 39.875, 54000.0],\n",
              "       [2, 39.0, 62250.0],\n",
              "       [1, 39.875, 64000.0],\n",
              "       [0, 35.0, 58000.0],\n",
              "       [2, 39.0, 52000.0],\n",
              "       [0, 48.0, 62250.0],\n",
              "       [1, 50.0, 83000.0],\n",
              "       [0, 37.0, 67000.0]], dtype=object)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2e09bc4",
      "metadata": {
        "id": "b2e09bc4",
        "outputId": "f6075fd9-7ea9-4db1-e9ae-7ccb920aec5b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.0, 0.0, 0.0, 44.0, 72000.0],\n",
              "       [1.0, 0.0, 0.0, 27.0, 48000.0],\n",
              "       [0.0, 1.0, 0.0, 39.875, 54000.0],\n",
              "       [0.0, 0.0, 1.0, 39.0, 62250.0],\n",
              "       [0.0, 1.0, 0.0, 39.875, 64000.0],\n",
              "       [1.0, 0.0, 0.0, 35.0, 58000.0],\n",
              "       [0.0, 0.0, 1.0, 39.0, 52000.0],\n",
              "       [1.0, 0.0, 0.0, 48.0, 62250.0],\n",
              "       [0.0, 1.0, 0.0, 50.0, 83000.0],\n",
              "       [1.0, 0.0, 0.0, 37.0, 67000.0]], dtype=object)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct =  ColumnTransformer(transformers =[('one hot', OneHotEncoder(),[0])],remainder = 'passthrough')\n",
        "x= ct.fit_transform(x)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d156c17",
      "metadata": {
        "id": "3d156c17",
        "outputId": "6ddeabf0-bbd8-4d3e-af6a-c422f8337bd3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0     No\n",
              "1    Yes\n",
              "2     No\n",
              "3     No\n",
              "4    Yes\n",
              "5    Yes\n",
              "6     No\n",
              "7    Yes\n",
              "8     No\n",
              "9    Yes\n",
              "Name: Purchased , dtype: object"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = df1.iloc [:,3]\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc50ba28",
      "metadata": {
        "id": "bc50ba28",
        "outputId": "20c335eb-5d77-4f96-ef32-ca91ec8a14be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes'],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = df1.iloc [:,3].values\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca422d75",
      "metadata": {
        "id": "ca422d75",
        "outputId": "2b33c7ff-a0a9-4d51-a7c8-2d8fd0a9d5c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 0, 0, 1, 1, 0, 1, 0, 1])"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "yle = LabelEncoder()\n",
        "y=yle.fit_transform (y)\n",
        "y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb276307",
      "metadata": {
        "id": "cb276307",
        "outputId": "f22c6120-c9e9-4063-c77b-a4761c07c904"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.0, 0.0, 0.0, 44.0, 72000.0],\n",
              "       [1.0, 0.0, 0.0, 27.0, 48000.0],\n",
              "       [0.0, 1.0, 0.0, 39.875, 54000.0],\n",
              "       [0.0, 0.0, 1.0, 39.0, 62250.0],\n",
              "       [0.0, 1.0, 0.0, 39.875, 64000.0],\n",
              "       [1.0, 0.0, 0.0, 35.0, 58000.0],\n",
              "       [0.0, 0.0, 1.0, 39.0, 52000.0],\n",
              "       [1.0, 0.0, 0.0, 48.0, 62250.0],\n",
              "       [0.0, 1.0, 0.0, 50.0, 83000.0],\n",
              "       [1.0, 0.0, 0.0, 37.0, 67000.0]], dtype=object)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e66b0880",
      "metadata": {
        "id": "e66b0880",
        "outputId": "f8ebd9f0-b9ca-4be9-b05c-ff826e523c69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     0         1    2         3         4\n",
            "0  1.0 -0.654654 -0.5  0.664912  1.002707\n",
            "1  1.0 -0.654654 -0.5 -2.075331 -1.465494\n",
            "2 -1.0  1.527525 -0.5  0.000000 -0.848444\n",
            "3 -1.0 -0.654654  2.0 -0.141042  0.000000\n",
            "4 -1.0  1.527525 -0.5  0.000000  0.179973\n",
            "5  1.0 -0.654654 -0.5 -0.785805 -0.437077\n",
            "6 -1.0 -0.654654  2.0 -0.141042 -1.054127\n",
            "7  1.0 -0.654654 -0.5  1.309675  0.000000\n",
            "8 -1.0  1.527525 -0.5  1.632056  2.133965\n",
            "9  1.0 -0.654654 -0.5 -0.463423  0.488498\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "std_sca= StandardScaler()\n",
        "x_STD = std_sca.fit_transform(x)\n",
        "print (pd.DataFrame(x_STD))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4fcc4e5",
      "metadata": {
        "id": "d4fcc4e5",
        "outputId": "496c32ce-e8b3-4fc3-a7db-5d3e503dfff4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     0    1    2         3         4\n",
            "0  1.0  0.0  0.0  0.739130  0.685714\n",
            "1  1.0  0.0  0.0  0.000000  0.000000\n",
            "2  0.0  1.0  0.0  0.559783  0.171429\n",
            "3  0.0  0.0  1.0  0.521739  0.407143\n",
            "4  0.0  1.0  0.0  0.559783  0.457143\n",
            "5  1.0  0.0  0.0  0.347826  0.285714\n",
            "6  0.0  0.0  1.0  0.521739  0.114286\n",
            "7  1.0  0.0  0.0  0.913043  0.407143\n",
            "8  0.0  1.0  0.0  1.000000  1.000000\n",
            "9  1.0  0.0  0.0  0.434783  0.542857\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "Nm_x= MinMaxScaler()\n",
        "x_NOR = Nm_x.fit_transform(x)\n",
        "print (pd.DataFrame(x_NOR))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8b72051",
      "metadata": {
        "id": "f8b72051",
        "outputId": "127f51b6-fa49-4308-ea5e-32545ba89472"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          0         1         2         3    4\n",
            "0  0.000014  0.000000  0.000000  0.000611  1.0\n",
            "1  0.000021  0.000000  0.000000  0.000562  1.0\n",
            "2  0.000000  0.000019  0.000000  0.000738  1.0\n",
            "3  0.000000  0.000000  0.000016  0.000627  1.0\n",
            "4  0.000000  0.000016  0.000000  0.000623  1.0\n",
            "5  0.000017  0.000000  0.000000  0.000603  1.0\n",
            "6  0.000000  0.000000  0.000019  0.000750  1.0\n",
            "7  0.000016  0.000000  0.000000  0.000771  1.0\n",
            "8  0.000000  0.000012  0.000000  0.000602  1.0\n",
            "9  0.000015  0.000000  0.000000  0.000552  1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import Normalizer\n",
        "Nm_x= Normalizer()\n",
        "x_NOR = Nm_x.fit_transform(x)\n",
        "print (pd.DataFrame(x_NOR))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d82cf41",
      "metadata": {
        "id": "2d82cf41"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54a8e929",
      "metadata": {
        "id": "54a8e929"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5a9aa47",
      "metadata": {
        "id": "c5a9aa47"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f8a77a0",
      "metadata": {
        "id": "9f8a77a0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}